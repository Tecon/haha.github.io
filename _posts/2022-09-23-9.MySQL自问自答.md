---
title:  "MySQL自问自答"
author:
  name: liuhe
  link: https://tecon.github.io
date:  2022-09-17 06:46:49 +0800
categories: [work, 利其器]
tags: [MySQL, 学习纪要]
toc: false
---

> 文章中未说明版本时以MySQL8.0为准

### 1、mysql的结构是怎么样的？

mysql是插件式的数据库管理系统，整体分为server层和引擎层，server层用于管理连接和用户权限、执行sql语句的分析与优化；引擎层用于实际数据的管理，可以实现插件式的装载与移除，故而可以选用不同的存储引擎。

![Mysql Architecture With Pluggable Stroage Engines](https://dev.mysql.com/doc/refman/8.0/en/images/mysql-architecture.png)

### 2、何为存储引擎，为何要有存储引擎？不同的mysql存储引擎有哪些优劣、适用场景

作为数据库管理系统，核心功能是数据的管理，围绕数据的管理需要有连接管理、权限管理、sql语句分析与执行等相关功能，核心功能单独抽出来作为存储引擎，实现插件式的load与unload，一方面大大增强了整个dbms的可扩展性，针对不同场景的数据管理可以选用特定的存储引擎，大大提升数据管理的效率。另一方面，通过引擎层包装数据管理细节，应用开发者仅需关心一致性的server层api（sql语法）即可，可以快速的进行代码开发与移植。

MYSQL存储引擎一览

| 存储引擎  |  特性 | 缺点 | 注意事项   | 适用场景  |
| :-------: | :---------: | :---------: | :-------: | :-------: |
|  InnoDB   | 支持行锁、事务、一致性读、外键、自适应hash索引、MVCC；通过聚簇索引实现索引组织表 [详见](https://dev.mysql.com/doc/refman/8.0/en/innodb-introduction.html) |                          |                   | mysql默认存储引擎，适用于绝大多数场景，如电商、社区、ERP等 |
|  MyISAM   | 支持外键、B-tree索引，表级锁；[详见](https://dev.mysql.com/doc/refman/8.0/en/myisam-storage-engine.html) | 不支持hash索引；不支持事务 | 8.0不再支持分区表 |                                      |
|  Memory   | 数据存储在内存中；表级锁；支持hash索引、B-tree索引 | 关机数据丢失 |                   | 适用于存储瞬时数据或缓存，如session信息 |
|    CSV    | 数据以csv格式存在磁盘，metadata以同名的csm文件存储。以sql语句管理csv文本文件 | 数据容易人为损坏 |                   | 需要和其他文本处理工具协同使用的场景，如Excel表格处理 |
|  Archive  | 适合归档存储数据 | 不支持索引、分区表、delete、update |                   | 主要用于存储大量的无索引归档数据 |
| BlackHole | 不存储数据；binlog为statement时存储binlog |                          |                   | 做binlog过滤或查找与存储引擎无关的性能瓶颈 |
|   Merge   | 是MyISAM引擎相同表的merge，和分区表相对应 |                          |                   |                                      |
| Federated | 允许访问远程MySQL，从federated存储引擎查询数据会自动从远程MySQL拉数据 | 本身不存储任何数据 |                   |                                      |
|  Example  |                                                              | 不支持索引，不支持分区表 |                   | 仅仅在源码中用于展示如何写一个新引擎 |
| 其他第三方引擎 | |  | |  |

### 3.1、mysql是如何组织数据的

在mysql中数据的组织由存储引擎实现，这里仅介绍使用最广泛的存储引擎-InnoDB的数据组织形式

innodb中数据存储在磁盘文件中，同时会利用内存作为缓存加速数据的读写，架构如下：

<img src="/2022/09/upgit_20220923_1663908632.png" alt="InnoDB Architecture" style="zoom: 67%;" />

Innodb中的数据包括实际数据以及维护实际数据所需的索引数据，通过聚簇索引这种数据组织形式维护数据。

#### 数据存储的逻辑结构：

逻辑结构分级组织，依次为 **表空间(tablespace) --> 段(segment) --> 区(extent) --> 页(page)**，页内为物理存储结构：一行一行的数据。

<img src="/2022/09/upgit_20220923_1663908656.png" alt="image-20220918075135239" style="zoom:50%;" />

**表空间**

表空间是Innodb逻辑存储的最高层，所有需要持久化的数据都会存储在表空间中。根据不同的用途，表空间分为系统表空间、通用表空间、独立表空间、Undo表空间、临时表空间。

- 系统表空间（System TableSpaces）

​        innodb会默认创建名为ibdata1的文件，这就是系统表空间的物理存储，系统表空间用于存储buffer pool，未启用独立表空间时表的索引和数据，双写buffer pool（8.0.20+后移出系统表空间，独立存储）等这些公共的共享的数据

- 通用表空间（General Tablespaces）

​        通用表空间需要使用`CREATE TABLESPACE`语法创建，它也是一个共享表空间，只用于存储用户定义表的索引和数据，而不会存储其他诸如buffer pool这类共享数据

- 独立表空间（file-per-table Tablespaces）

​        innodb默认开启`innodb_file_per_table`（5.6.6+），每个innodb表都会在data的对应scheme目录下单独创建`表名.ibd`文件存储。使用独立表空间在存储占用（可释放）、行格式支持（Dynamic和Compressed）、外挂存储、数据恢复、数据备份、表空间占用监控等方面相比使用共享的系统表空间或通用表空间具有很大的优势，当然，也需要更多的文件描述符、更多的打开文件、更多潜在的存储碎片、更多的文件句柄等系统资源，不过整体来讲，仍然是使用独立表空间更具优势，因此，除非特殊场景，尽量使用独立表空间存储表

- Undo表空间（Undo Tablespaces）

​        Undo表空间就是用来存储undo-log的，用于事物回滚操作。MySQL实例初始化时系统会在`innodb_undo_directory `目录下创建2个默认的Undo表空间文件undo_001和undo_002用于后续存储undo log

- 临时表空间（Temporary Tablespaces）

​        innodb的临时表空间分为`session临时表空间`和`全局临时表空间`。session临时表空间用于存储用户创建的临时表和mysql系统优化器创建的临时表（8.0.16+）。全局临时表空间(ibtmp1)存储了用户定义临时表的回滚信息

**段（segment）**

MySQL使用B+树索引组织表，树有非叶子节点作为稀疏索引用于查询叶子节点，叶子结点存储实际索引和数据；如果将这两部分一起存储，将会出现大量随机IO，因此innodb引入**段**的概念，常见的段有数据段、索引段、回滚段等。段是一个逻辑上的概念，并不对应表空间中某一个连续的物理区域，它由若干个完整的区组成（还会包含一些碎片页），不同的段不能使用同一个区。

存放叶子节点的区的集合就是`数据段`，存放非叶子节点的区的集合就是`索引段`。每个索引在Innodb中都会存在于2个段，一个是B树中的非叶子结点，用于索引数据（索引段），另一个是叶子节点，存储实际的数据（数据段）

表空间中的段初始化时会一次性分配32个页，之后再次分配空间时将以区为单位，对于比较大的段（类似LRU思想）Innodb最多一次分配4个区。

**区（extent）**

n个页组成了一个区，页大小不同时n也不同，当页大小<=16k时，一个区即1M（64个连续16k、32个8k...），页大小为32k时，区大小为2M，64k时，区大小为4M。使用[`SHOW TABLE STATUS`](https://dev.mysql.com/doc/refman/8.0/en/show-table-status.html) 统计表空间中的空闲空间时，Innodb会统计所有的空闲区大小，需要注意的是，Innodb会预留一些区用于清理以及其他内部操作，这些区是不算入空闲区的

**页（page）**

页是innodb进行读写的最小存储单位，默认大小为16k，可以通过设置`innodb_page_size`修改。数据在内存和磁盘间写入写出也是也页为单位。出于不同的目的innodb设计了多种不同的页类型：FIL_PAGE_INDEX，FIL_PAGE_UNDO_LOG，FIL_PAGE_INODE，FIL_PAGE_IBUF_FREE_LIST。

页由7部分组成

- Fil Header
- Page Header
- Infimum + Supremum Records
- User Records
- Free Space
- Page Directory
- Fil Trailer

其中，Fil Header - Fil Trailer、Page Header - Page Directory两对字段，分别用于记录对外的页信息（如属于那个space或log、pre和next页指针、页的checksum以及和页开头的LSN以标识页结束）和对内的页信息（如页内有多少条记录、空闲区域指针、按索引递增顺序组织的位置指针以便二分查找），Infimum + Supremum Records用于记录下限和上限，User Records用于记录用户数据，Free Space用于分配新数据。Innodb采用稀疏槽来维护索引位置指针，即并非每个数据的索引都会在Page Directory里面有记录（full page每6条记录有一个slot），因此，在record里面的extra字段中需要借助n_owned来标识有几条记录属于当前slot/record

**记录（record）**

一条记录即对应物理意义上的一行数据，只是一个record存的除了一行数据，还有一些信息用于维护这行数据，这些数据共同组成了一条record

逻辑上，record由3部分组成（物理组成取决于row format，略有差异）

| **Name**            | **Size**                                                |
| ------------------- | ------------------------------------------------------- |
| Field Start Offsets | (Number Of Fields \* 1) or (Number Of Fields * 2) bytes |
| Extra Bytes         | 6 bytes                                                 |
| Field Contents      | depends on content（包括系统字段、用户自定义字段）      |

Field Start Offsets记录了字段在Field Contents的起始位置，Field Contents记录了系统的以及用户定义的字段（使用相应字符集编码），Extra Bytes用于维护当前记录是否删除、在整个页中的位置、字段数目、页中下一条record记录地址等信息

#### 数据存储的物理结构：

数据存储在介质上，要么按照其本身的逻辑结构组织，要么基于读写性能、存储效率等考虑做特异性存储（如映射、倒排索引等）。显然，对于常见的数据及场景，前一种方式更具有普适性，而MySQL正是使用这种方法组织数据的物理结构--将数据逐行存储。对于存储的每一行数据，是一个字段一个字段紧挨着存放并以下标来记录字段的开始结束，还是用分隔符将各个字段分隔后存放，或者数据紧挨存放并按照实际数据类型记录长度信息用于索引，这种不同的存储形式就是行格式。

MySQL最小存储单位为页，读写以页为单位进行，页中有一行一行的数据。由于MySQL使用页作为最小的访问单位，当行内业务数据太大就会导致一页只能放一行甚至一行都存储不了，这样存储结构B+树将退化为链表，不利于高效的读写访问，因此，MySQL的每一页数据内最少有2行数据，当行数据过于长（一页无法存2行），将会对某些字段拆分存储，原始行仅存储部分信息，而具体拆分策略取决于行格式。

行格式决定了MySQL中的数据在磁盘上的物理结构，InnoDB存储引擎支持4种行格式（5.0.3 - 5.6版本的默认行格式是COMPACT，5.7+改为DYNAMIC，可通过`innodb_default_row_format`参数更改）

|   行格式   | 紧凑存储 | 增强变长列存储 | 大的前缀索引支持 | 压缩支持 |          支持的表空间类型          |
| :--------: | :------: | :------------: | :--------------: | :------: | :--------------------------------: |
| REDUNDANT  |    否    |       否       |        否        |    否    | 系统表空间、独立表空间、通用表空间 |
|  COMPACT   |    是    |       否       |        否        |    否    | 系统表空间、独立表空间、通用表空间 |
|  DYNAMIC   |    是    |       是       |        是        |    否    | 系统表空间、独立表空间、通用表空间 |
| COMPRESSED |    是    |       是       |        是        |    是    |       独立表空间、通用表空间       |

**Redundant行格式**

Redundant行格式主要为了兼容老版本（5.0以下）的MySQL，行数据如下：

![image-20220919131629067](/2022/09/upgit_20220923_1663908672.png)

Redundant行格式顺序存储每一列数据，通过逆序存储的**字段偏移列表**实现不同字段的区分，同时使用6字节的**头信息**来记录向下一行的指针和维护行级别的锁，头信息的最后2个字节记录指向下一条记录的header尾部的指针

- 聚簇索引记录包含所有的用户定义字段，同时会有**事务ID列**和**回滚指标列**来支持事务及实现回滚，另外如果表没有定义主键，则在聚簇索引列中的RowId是由MySQL生成一个6字节的id，否则RowID存储主键

- 二级索引记录会包含不在该索引内的所有的主键列。

- 超大字段拆分方式：对于超过768字节的数据列，Redundant行格式的拆分策略为存储前768字节，然后是20字节的列实际长度和溢出页地址指针（同Compact行格式，见下图）

**Compact行记录格式如下**

Compact行格式相比Redundant行格式，以CPU占用的提升换来了存储占用降低20%左右，适用于IO密集型和缓存命中率较低的应用场景。行数据如下：

![image-20220919131700550](/2022/09/upgit_20220923_1663908683.png)



Compact行格式也是顺序存储每一列数据，不过它通过**变长字段长度列表**、**NULL标识位**、**记录头信息中的字段长度**来区分每一个字段，同时使用5字节的头信息记录指向下一行的指针和维护行级的锁(详细作用机制待补充)，头信息的最后2个字节记录指向下一条记录的header尾部的指针，头信息详细如下图

![compact_header](/2022/09/upgit_20220923_1663908695.png)

- Compact行格式使用**变长字段长度列表**来维护所有可变长度字段的实际长度（逆序存储，每个字段占用1-2字节来存储长度，所有列长度固定时，该字段不存在），使用**NULL标识位**来记录字段是否可以为NULL，该字段长度为 **取上限(允许为NULL的字段数 / 8)**字节，即每bit表示一位（逆序存储，当所有列NOT NULL时，该字段不存在）

- 记录头信息包含了可变长度字段信息（变长字段长度列表、NULL标志位），其后跟着非空字段（空字段除了在NULL标识位中占位，不占用实际存储空间）

- 聚簇索引记录包含所有的用户定义字段，同时会有事务ID列和回滚指标列来支持事务及实现回滚，另外如果表没有定义主键，则在聚簇索引列中的RowId是由MySQL生成一个6字节的id，否则RowID存储主键。

- 二级索引记录会包含不在该索引内的所有的主键列

- 超大字段拆分的方式与Redundant格式一致：对于超过768字节的数据列，Redundant行格式的拆分策略为存储前768字节，然后是20字节的列实际长度和溢出页地址指针

**Dynamic行格式**

Dynamic行格式与Compact行格式基本相同，带来了2项改进，一是改进了对于超长可变长度列存储的支持，二是添加了对大索引前缀的支持。

- Dynamic行格式是基于**如果一个超长字段的一部分需要离页存储，那么将整个超长字段存储在溢出页上通常能带来更高的效率**这样的思想构建的，因此，相比于Compact行格式，Dynamic行格式在拆分超大字段时，将整个字段存储在溢出页，原始行仅在该字段位置存储指向溢出页的长度为20字节的指针。至于如何衡量字段是否超大，取决于字段长度和行数据的总长度，当行数据无法成为B树的节点时（单页存储少于2行，B树退化为链表），最大的字段将离页存储，直到该行可以fit一个B树节点

- Dynamic行格式的支持的索引前缀长度最大3072字节

- 使用Dynamic行格式的表可以存储在系统表空间、独立表空间、通用表空间

**Compressed行格式**

Compressed行格式与Compact行格式基本相同，额外添加了表和索引的压缩存储支持。

- Compressed行格式的支持的索引前缀长度最大3072字节



### 3.2、MySQL使用B+树存储数据体现在哪里？

聚簇索引、普通索引都是使用B树组织，存储数据的叶子节点的页会有指向pre和next的指针（Page的Fil Header有FIL_PAGE_PREV和FIL_PAGE_NEXT），所以才说是B+树，聚簇索引记录上面存储了所有的用户定义字段（索引组织表）



### 4、如何优化sql语句

对于sql语句引起的性能问题，主要分为两大类，一是如update、delete或ddl语句引起IO猛增或其他阻塞正常sql语句的动作，造成大量正常sql无法执行，二是select语句使用不当导致sql查询时间偏高

对于查询语句，通过explain分析，查看是索引使用不当还是sql语句不当，或者mysql选择的索引不当，索引使用问题和sql语句就需要优化sql语句使得命中正确的索引或者建立合适的索引；mysql选择的索引不当的情况下，可以通过force index语句强制使用合适的索引或者重建索引触发mysql选择合适的索引（后者建议在业务较轻的时间段执行，且对于大表的执行需预先评估）。通过索引覆盖减少回表操作（select了索引字段）。通过索引下推（MySQL5.6+）减少存储引擎返回给server层执行where匹配操作的数据，提升查询效率（where中有多个索引字段，一次性匹配）。

对于update和delete，尽量避免大事务，尽可能的分批分次执行

对于ddl，如添加索引，移除索引，添加字段，移除字段（可以不移除字段哈，就留着就行，反正不怎么占用磁盘）等。添加字段可以放在最后一个字段，以便mysql可以使用秒级加字段优化

### 5、如何及时发现mysql线上问题？有何规避或预防手段

#### 5.1、发现线上问题

发现线上问题的良好手段就是完善的监控，实现mysql实时监控可以从两方面入手，一是通过mysql自带的功能实现监控：

1. 可以通过监控预先设置的查询或者修改语句的正确性检测mysql的健康状态
2. 通过`set global slow_query_log=1;`开启慢日志监控；并设置慢日志阈值`set global long_query_time=200;`来启用mysql慢查询日志发现慢sql
3. MySQL 5.6版本之后提供了`performance_schema`库，在`file_summary_by_event_name`表中统计了每次io请求的时间，表中`event_name='wait/io/file/innodb/innodb_log_file'`为redolog的相关时间监控，`event_name='wait/io/file/sql/binlog'`为binlog的相关时间监控，可以开启实时监控统计相关信息（注意有性能损耗，经人测试损耗在10%左右）

另一个是通过监控与mysql交互的中间件实现mysql的数据监控，在数据库中间件中集成监控相关代码，对于每个sql语句的执行过程进行监控上报，如sql解析，优化器选择，存储引擎执行时间，配合相关的报警插件及时通知到开发负责人

#### 5.2、规避或预防线上问题

一是从设计上尽可能规避问题，比如：

- 选用innodb引擎，以达到crash-safe的目的、实现对事务的支持；
- binlog使用row格式（除了某些极个别固定场景使用statement或mixed），以保证支持其他业务准确使用binlog；
- 隔离级别选用rc（配合使用row格式的binlog），支持事务的同时最大限度的提升并发度（需要注意业务对rr或其他隔离级别没有严格要求）

二是在使用过程中尽量规避问题，这个主要通过建立并严格遵守完善的sql规范来实现。如：

- 禁用join操作
- 分页查询最多查询5w条
- 线上禁用触发器及外键（此类操作具有隐蔽性，不利于后续维护）
- 禁止批量操作大批数据（分批分次执行，如每次200条，执行100次）
- 尽量避免大事务（如一次性删除100w数据）
- 事务中最耗时的sql操作放在最后
- 尽量避免数据库做大量复杂的计算操作（将计算操作放在易于横向扩展的server层）
- ddl语句必须走工单执行，事前进行时间、影响范围评估，尽量放在业务较轻的时间段执行
- 修改数据行为必须走工单执行，工单必须有回滚脚本，且说明修改前后影响
- 上线select语句前进行explain评估，尽量使用索引及索引覆盖等优化技术，避免使用文件排序、全表查找

#### 5.3、为何mysql默认的隔离级别是RR，实际生产中你们使用了什么隔离级别，为什么

隔离级别有四个，读未提交、RC、RR、序列化，序列化性能太差，读未提交存在脏读问题，因此RC和RR比较适合作为默认隔离级别。对比RC和RR，配置RC隔离级别、statement格式的binlog时，在出现事务乱序时，备库重放SQL会导致主备数据不一致，所以MySQL选择了RR作为默认隔离级别。

实际使用中大多选择了RC，相比RR，一方面使用RC时仅需加行锁即可，可以提升访问并发度，另一方面无需加gap lock，锁定的范围较小（只有当前行），产生死锁的概率大大降低

### 6、mysql有哪些比较棒的设计思想，在哪些场景下运用该思想获得了性能提升

- 随机操作优化成顺序操作从而大幅提升读写性能。根据空间局部性原理，通过redolog将随机写入优化为顺序写入；通过changebuffer将随机读取变为顺序读取；应用rowlog时如果隔壁的数据也是脏数据，将触发数据merge；范围查询时筛选出符合条件的id值放入read_rnd_buffer递增排序后到主键索引树查询记录明细并返回（MRR）；join操作中运用MRR优化将NLJ优化为BKA；
- 通过缓存数据大幅提升查询性能。根据时间局部性原理，buffer poll维护lru数据，以加快最近访问的数据的查询效率
- 单次操作改为批量操作以提升效率。如binlog和redolog写入时，可以通过设置sync_binlog=N（N>1）累计N个事务后执行fsync触发刷盘；设置`innodb_flush_log_at_trx_commit=2`触发事务提交时仅将redolog写入page cache，由文件系统自行控制批量将page cache写入磁盘而不是直接写入磁盘（`innodb_flush_log_at_trx_commit=1`）

### 7、各种概念区分

#### rowId、commit_id、trxId、Xid、LSN、GTID、threadId

**`rowId`**：当用户未指定表的主键且没有非空唯一键时，Innodb生成一个6字节的rowId（循环使用）作为当前记录主键（注意：有非空唯一键则非空唯一键为主键，多个唯一键时，使用第一个唯一键的字段作为主键。唯一键一定要定义为非空，唯一联合索引的每一个字段也一定要是非空，不然有null字段时看起来是一样的，但是MySQL认为是不一样，插入了不唯一数据）

**`commid_id`**：事务提交时，生成对应的commit_id。当启用redo log的组提交时，同一组提交的事务具有相同的commit_id

**`trxId`**：Innodb的事务id，事务开始时申请的，按照申请顺序严格递增，用于标记不同的事务。当事务修改某条记录时，trx_id将会写入该记录的row_trx_id中，表示当前数据由trx_id生成，同时在undo log中也会记录当前undo log对应的是哪个trx_id，用于在其他事务需要查看当前数据的历史版本时计算。

**`Xid`**：server层的事务id。内存维护`global_query_id`（8字节，循环使用），赋给`query_id`，第一个事务的Xid即为query_id，实例重启后生成新的binlog文件，顾同一binlog文件内事务的Xid不同，不同事务的Xid可能相同（循环使用）

**`LSN`**：全称log sequence number，单调递增，用来对应redo log的一个个写入点。**每次写入长度为length的redo log， LSN的值就会加上length**。LSN会记录在数据页的`Fil Header`的`FIL_PAGE_LSN`字段中，用于表示当前页最近的一条log记录；同时也会记录在文件的第一页的`FIL_PAGE_FILE_FLUSH_LSN`中标识已刷新到磁盘的最大LSN。

**`GTID`**：全称Global Transaction Identifier，也就是全局事务ID，是一个事务在提交的时候生成的，是这个事务的唯一标识。它由两部分组成`GTID=server_uuid:gno`。**用于主从架构下，主库故障，从库上线切换过程同步数据的过程**。同步数据原来有**基于位点的同步**，需要开发人员手动识别、跳过故障sql位点、建立新的同步关系，操作复杂。MySQL5.6引入GTID的概念，使用GTID标识一个全局唯一事务，使用**基于GTID的同步**时，只需要开发人员修改主从关系建立新的同步关系即可，MySQL将检查新的主从关系间GTID的包含关系，实现事务同步

**`threadId`**：当前session的线程id，在创建临时表时，临时表在内存中的唯一区分(db+table+serverId+threadId)需要用到，且主从复制时，相应临时表的binlog记录也会将threadId传递给从库

#### change buffer、insert buffer、log buffer、sort_buffer、join_buffer

**`change buffer`**：

当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB会将这些更新缓存在change buffer中，这样就无需从磁盘中读入这个数据页了

在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行change buffer中与这个页有关的操作。

将change buffer中的操作应用到原数据页，得到最新结果的过程称为merge。除了访问这个数据页会触发merge外，系统有后台线程会定期merge。在数据库正常关闭（shutdown）的过程中，也会执行merge操作。

change buffer在内存中，有buffer pool分配空间，可以通过参数innodb_change_buffer_max_size来动态设置大小。这个参数设置为50的时候，表示change buffer的大小最多只能占用buffer pool的50%。持久化到磁盘时，change buffer写入到系统表空间

唯一索引的更新不适用change buffer，因为必须将数据写入内存判断唯一性约束。使用change buffer时，当页内需要merge的记录越多，节约的开销越大，性能改善越明显，反之，非但不能改善，反而带来性能损失。因此，**change buffer适用于账单类、日志类这种写完以后马上被访问到的概率比较小的系统**，对于写完之后很快就要访问的数据不适用change buffer

**`insert buffer`**：

change buffer的前身，仅针对insert优化（非主键的非唯一索引有效），之后升级了，增加了对update/delete的支持，并改名为change buffer

**`log buffer`**：

log buffer是日志写入磁盘前保存日志的内存区域，这些数据会定期写入磁盘。该内存区域大小由[`innodb_log_buffer_size`](https://dev.mysql.com/doc/refman/8.0/en/innodb-parameters.html#sysvar_innodb_log_buffer_size) 决定，默认16M，大的log buffer允许执行修改大量数据的事务在提交前仅写内存，因此，如果在特定场景需要执行大量的大事务，可以适当提高这个缓存。[`innodb_flush_log_at_trx_commit`](https://dev.mysql.com/doc/refman/8.0/en/innodb-parameters.html#sysvar_innodb_flush_log_at_trx_commit)变量定义了log数据write和fsync的时机，[`innodb_flush_log_at_timeout`](https://dev.mysql.com/doc/refman/8.0/en/innodb-parameters.html#sysvar_innodb_flush_log_at_timeout) 变量定义了刷盘频率。

**`sort_buffer`**：

使用Explain查看执行计划时，在Extra中可能会有`Using filesort`，表示需要排序，MySQL给需要排序的线程分配一段内存用于排序，这块内存就是`sort_buffer`，大小由`sort_buffer_size`决定，排序数据（select的所有数据）超出该大小就会使用磁盘临时表来辅助排序，这就是`全排序`。`max_length_for_sort_data`字段决定了要排序的数据是否太长而启用`rowId排序`，启用rowId排序时sort_buffer仅存储要排序的字段和主键id，排好序后回表取出select的字段返回

**`join_buffer`**：

join_buffer与sort_buffer类似，是在需要做join操作时，MySQL给相应的线程分配的内存块。join_buffer的大小是由`join_buffer_size`决定，默认256k。a、b做join，a符合条件的放入join_buffer，b和buffer中数据比较，取得结果集。当join_buffer的大小不足以放下所有满足条件的a记录，则分段处理（一段一段放入buffer，做join，处理结果集）

#### buffer pool、double-write buffer

buffer pool（bp）是InnoDB引擎在内存中开辟的一块用于缓存数据和索引的区域。上文提到的各种buffer，MySQL的数据页缓存就存储在bp中。在bp内部，使用变种的LRU算法管理list结构的数据。详细参考[这篇还没写的文章]()

double-write buffer是Innodb在将buffer pool里面的页数据写入到适当的磁盘文件前的数据存储区域，它是存储在系统表空间的一块区域（8.0.20+移出系统表空间独立存储了）。主要是为了应对在写page（默认16k）到一半（磁盘一般默认4k）情况下系统宕机的情景，此时可以在double-write buffer中找到对应的数据备份用于故障恢复。

原理是：在将bp中的页写入磁盘对应的文件前，先将bp中的页copy到double-write buffer，然后将double-write buffer内存中的数据每次1M，顺序的写入double-write buffer对应的磁盘文件上并立即调用fsync函数刷磁盘，double-write buffer写磁盘完成后，再将double-write buffer中对应的页写入这个页本身所属的磁盘文件（例如数据页）

通过上述的过程可以看到，虽然做了数据copy，但是并不会造成2倍的IO增加，因为数据是以一个个顺序的大块执行写入并调用单次的fsync刷新到磁盘上的。

#### redo log、undo log、binlog、row log、relay log

**`redo log`**：

redo log是基于磁盘存储的用于在系统crash之后恢复因为未完成的事务操作而损坏的数据的数据结构（redo log在内存中有redo log buffer对redo log缓冲，用于提升性能）。redo log是Innodb独有的特性，是Innodb存储引擎实现crash-safe功能的核心。

redo log主要记录了事务对数据页(Page)的物理修改，在固定大小的磁盘文件上顺序存储，采用循环写的方式。redo log是物理逻辑结合型的日志，具体是哪个page是物理操作，而page内的变化是逻辑操作；这种方式既实现了物理日志的幂等性（以实际存储页为整体），又拥有逻辑日志的轻量性（页内修改是逻辑日志）。当有数据变更时，就会记录一条redolog到文件中(实际是先写buffer)，同时，在redo log文件中存在一个称为checkpoint的位点，这个位点标记了已刷盘和未刷盘的redo log分界，已刷盘的日志可以被新的redo log覆盖，未刷盘日志不能被覆盖，当所有日志都未刷盘，更新等操作将无法继续进行。checkpoint实际标记的是相应位置的redo log的LSN，而不是位置信息，LSN全称Log Sequence Number，递增数字，每条redo log都会分配一个LSN。

使用redo log进行崩溃恢复时的流程：

1. 如果redo log里面的事务是完整的，即已经有了commit标识，则提交
2. 如果redo log里面的事务只有prepare，则通过XID到binlog文件中找到binlog判断binlog完整性
  - binlog完整，则提交事务
  - binlog不完整，回滚

判断redolog是否完整是通过是否有commit标识，那判断binlog是否完整是通过什么呢？

> binlog有相应的格式，statement格式在结尾有COMMIT，row格式在最后有XID event

redo log如何关联对应的binlog？

> redolog和binlog有一个共同的由server层生成的事务id字段-XID，崩溃恢复时，扫描redolog，有commit的就直接commit，没有commit只有prepare的就拿着XID找binlog。

**`binlog`**：

binlog是MySQL server层实现的逻辑日志，无论什么存储引擎，都会有binlog产生，实现主从复制的日志文件（表空间是Innodb的概念，binlog是MySQL server层实现的日志）。它是增量写文件，可以根据大小、时间切割，以方便恢复数据。binlog有3种格式

- statement：记录原始的sql语句，丢失了修改前的数据，且无法和RC隔离级别一起使用（事务乱序可能导致主从数据不一致），生产中使用不多
- row：记录数据完整的修改前和修改后，占用空间大，但是信息详细，普遍应用于实际生产中，生产中有大量依赖binlog修改前后值来实现业务逻辑的场景
- mixed：结合以上两种，如果可能引起主备不一致就用row，否则用statement，使用较少的原因还是信息不够完整

**`undo log`**：

undo log是用来支持实现一致性读的数据结构。它记录了如何undo事务对聚簇索引记录的最近的修改，当其他事务要看当前记录的原始版本时，可以通过undo log计算出origin data。undo log存储在[rollback segments](https://dev.mysql.com/doc/refman/8.0/en/glossary.html#glos_rollback_segment)中的[undo log segments](https://dev.mysql.com/doc/refman/8.0/en/glossary.html#glos_undo_log_segment)中，rollback segment存储在undo表空间和临时表空间。

**`row log`**：

使用`alter table A engine=Innodb`重建表过程中，对原始表的更新操作日志记录

**`relay log`**：

主从同步时，将主机的binlog同步到从机的relylog中，然后从机读取relylog恢复数据

#### sync_binlog、innodb_flush_log_at_trx_commit

sync_binlog：控制binlog的write（binlog写入Page cache）和fsync（Page cache持久化到硬盘）时机

> binlog cache  -->  page cache  -->  hard disk

- sync_binlog=0的时候，表示每次提交事务都只write，不fsync；

- sync_binlog=1的时候，表示每次提交事务都会执行fsync；

- sync_binlog=N(N>1)的时候，表示每次提交事务都write，但累积N个事务后才fsync；

innodb_flush_log_at_trx_commit：控制redolog的write和fsync时机

> redo log buffer -->  page cache  -->  hard disk

- 设置为0的时候，表示每次事务提交时都只是把redo log留在redo log buffer中;
- 设置为1的时候，表示每次事务提交时都将redo log直接持久化到磁盘；
- 设置为2的时候，表示每次事务提交时都只是把redo log写到page cache；

#### anaylize table、optimize table

`alter table t engine = InnoDB`是重建（recreate）表，将会创新新的临时表，然后复制数据，修改临时表名称为原有的表名。从5.6引入OnlineDDL起，就允许在执行期间执行增删改操作，只是不能执行其他DDL（持有MDL读锁），而且执行期间对原表的修改也会记录在row log中，执行完成后，应用row log到新表

`analyze table t `不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了MDL读锁

`optimize table t` 等于recreate+analyze

#### mvcc

全称Multi-Version Concurrency Control，同一条记录在数据库中可以存在多个版本就是MVCC。

MVCC的实现：

mvcc通过read-view和undo log来实现。

每条记录存储生成当前版本的trx_id（事务id），记为row trx_id，每条记录有undo log，undo log记录了如何将当前数据回退到某个特定版本（特定row trx_id的版本）。事务启动时（RR，RC是每条语句执行时），创建一致性视图（由当前正运行未提交的事务id数组和系统已分配的trx_id+1共同组成），然后根据需要确定使用当前版本数据或者使用通过undo log计算出的历史版本数据（快照读，则读快照数据；当前读，则读当前数据），从而实现了在多个版本同时存在的情况下并发的访问

#### 刷脏页

脏页指的是内存中已经修改了数据页，这些数据页在同步回磁盘上之前和磁盘数据不同，称为脏页（对应的，内存和磁盘数据相同的页称为干净页）。将脏页同步回它在磁盘上的对应的页的过程，称为刷脏页。

刷脏页的时机有：

- redo log文件写满了，需要将checkpoint向前推进。此时就需要将checkpoint向前推进的位置上的所有redo log中在内存对应的脏页刷盘
- 内存不足，或者是bp中的部分数据页被驱逐，此时如果被驱逐的数据页是脏页，则驱逐前也要刷脏页
- 系统空闲时刷脏页。innodb使用`innodb_io_capacity`来表示当前磁盘最大的IO能力，Innodb通过控制脏页比例和redolog写盘速度来控制刷脏页速度。脏页比例要多关注，不要经常超过75%。刷脏页有连坐机制，脏页隔壁页也是脏页则会一起刷，使用SSD时可以修改参数`innodb_flush_neighbors`关闭连坐机制
- MySQL关机前

#### 半同步（seni-sync）

默认配置下，MySQL主从库通过binlog来保持一致，主库事务提交后，将binlog日志写入磁盘，然后返回给用户，备库通过拉取主库的binlog来同步主库的操作，无法保证主备节点数据实时一致，只能保证最终一致，因此属于异步复制。

为保证在主备切换时，主备节点数据完全一致，MySQL提供了半同步复制，其实现原理为：事务在主库上执行完成，生成binlog并推送给备库，等待备库的ack消息，主库接收到备库的确认消息后，在返回给用户，事务完成。

半同步分为after-commit和after-sync两种：

after-commit：主库将事务commit之后，将binlog发给从库并等待ack，然后返回（从库commit前主库变更可见）

after-sync：主库将binlog发给从库，收到ack后，本机commit提交，然后返回（所有机器几乎同时commit）

### 8、知识点关联

#### LSN和redo log、checkpoint的关系

LSN全称Log Sequence Number，递增数字，每条redo log都会分配一个LSN。当有数据变更时，就会记录一条redolog到文件中(实际是先写buffer)，同时，在redo log文件中存在一个称为checkpoint的位点，这个位点和write position之间标记了未刷盘的数据，其余的是已刷盘的redo log，已刷盘的日志可以被新的redo log覆盖，未刷盘日志不能被覆盖，当所有日志都未刷盘，更新等操作将无法继续进行。checkpoint和write position实际标记的是相应位置的redo log的LSN，而不是位置信息。

#### 快照读、当前读

快照读指的是在某一时刻创建快照，后续的读取操作以这个快照中的数据为准。比如RC或者RR启动事务时创建的语句级快照（每条语句执行前算出新的视图）和事务级快照（事务开始前创建快照），后续事务中的读语句只能看到快照中的数据

当前读指的是读取的数据一定是当前最新的（假如有数据正在更新未提交，此时因为要获取S/X/行锁，所以会等待行锁释放后继续操作）。更新操作需要先读后写，这里是当前读。加锁的select操作也是当前读`select k from t where id=1 lock in share mode;（S锁，共享锁）`，`select k from t where id=1 for update; （X锁，排他锁）`



### 99、还有哪些地方不尽如人意或可以改进的

对于MySQL的二次开发和深度使用涉及不够，就不班门弄斧了



### 参考：

[https://dev.mysql.com/doc/refman/8.0/en/](https://dev.mysql.com/doc/refman/8.0/en/)

[https://dev.mysql.com/doc/internals/en/](https://dev.mysql.com/doc/internals/en/)

[MySQL45讲-极客时间](https://time.geekbang.org/column/article/67888)

[MySQL行格式](https://smartkeyerror.com/MySQL-physical-structure)

[MySQL的内存结构与物理结构](https://cloud.tencent.com/developer/article/1496453)

